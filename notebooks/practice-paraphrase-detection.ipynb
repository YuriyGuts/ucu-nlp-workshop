{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/ucu-bg.jpg\" alt=\"UCU Machine Learning Workshops 2017\" style=\"height: 400px; border: 2px solid #C08050\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: Day 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrase Identification on Quora Question Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a dataset that contains 400k pairs of question titles from Quora. For each question pair, a supervised label is given by a human annotator: whether both questions in the pair are considered to have the same intent (`is_duplicate = 1`) or not (`is_duplicate = 0`).\n",
    "\n",
    "Note that the human judgment about a particular pair being a duplicate can be subjective, so expect some \"noise\" in the target values.\n",
    "\n",
    "Your task is to build a model that, given two question titles, predicts whether they have the same intent. Some infrastructural parts are created for your convenience. Fill out the rest as you go along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Plan**\n",
    "\n",
    "1. You should start with a baseline model, which could be cosine similarity over BoW vectors. Optionally, you can try using TF-IDF afterwards and compare the results to simple counting.\n",
    "2. Then, try leveraging some pre-trained word embeddings (e.g. fastText on Wikipedia, or Word2Vec on Google News etc.) and calculating the Word Mover's Distance as a feature. You can also use this feature later in step 4.\n",
    "3. Then, encode the questions as fixed-length padded sequences of word embeddings, and create a neural network (e.g. with a Multi-Layer Perceptron architecture). You might want to allocate a separate validation set for picking the hyperparameters.\n",
    "4. (Advanced) Use BoW cosine similarity, TF-IDF cosine similarity, WMD, and the predictions of the neural network as features for a 2nd-level model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpful Modules and Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline models:\n",
    "\n",
    "* `gensim.models.wrappers.fasttext.FastText.wmdistance`\n",
    "* `sklearn.feature_extraction.text.CountVectorizer` and `sklearn.feature_extraction.text.TfIdfVectorizer`\n",
    "\n",
    "For neural models:\n",
    "\n",
    "* `keras.preprocessing.text.Tokenizer`\n",
    "* `keras.preprocessing.sequence.pad_sequences`\n",
    "* `keras.models.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the subsequent runs reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('quora-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_orig.is_duplicate.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the indices for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_train, ix_test = next(splitter.split(df_orig, df_orig.is_duplicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Training set length:', ix_train.shape)\n",
    "print('Test set length:    ', ix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">TODO:</span> Create features for your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(df_orig), 1))\n",
    "y = df_orig.is_duplicate.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[ix_train]\n",
    "y_train = y[ix_train]\n",
    "\n",
    "X_test = X[ix_test]\n",
    "y_test = y[ix_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X train:', X_train.shape)\n",
    "print('y train:', y_train.shape)\n",
    "print('X test: ', X_test.shape)\n",
    "print('y test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">TODO:</span> Train your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">TODO:</span> Make predictions from your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = np.random.uniform(size=y_train.shape)\n",
    "y_pred_test = np.random.uniform(size=y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_label = y_pred >= threshold\n",
    "    \n",
    "    print('Log loss: ', log_loss(y_true, y_pred))\n",
    "    print('Precision:', precision_score(y_true, y_pred_label))\n",
    "    print('Recall:   ', recall_score(y_true, y_pred_label))\n",
    "    print('F1 score: ', f1_score(y_true, y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
